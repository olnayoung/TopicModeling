# Latent Dirichlet Allocation (LDA)

LDA는 **각 문서의 토픽 분포**와 **각 토픽 내의 단어 분포**를 추정한다.

    <각 문서의 토픽 분포>
    ----------------------------------------
    문서1: 토픽A 100%
    문서2: 토픽A  70%  토픽B  30%
    문서3:             토픽B 100%

    <각 토픽 내의 단어 분포>
    ----------------------------------------
    토픽A: 축구 30%  야구 50%  농구 20%
    토픽B: 불법 70%  경찰 30%

![LDA](./LDA.png)

1. &alpha;, &beta;, K 정하기 (보통 &alpha;=0.1, &beta;=0.001. 이 값이 1에 가까워질수록 문서에 많은 토픽이 포함되고, 토픽에 많은 단어가 포함됨)
    
    1-1. 모든 문서에 대해 각 문서 별 토픽 분포 추정

    1-2. 모든 단어에 대해 각 단어 별 토픽 분포 추정
2. 각 문서내의 단어 w를 관측하며 알맞은 토픽에 할당